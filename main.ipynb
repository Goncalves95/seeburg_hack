{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/gitpod/.pyenv/versions/3.12.4/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/gitpod/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from pandas) (2.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/gitpod/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/gitpod/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/gitpod/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/gitpod/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: sqlalchemy in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (2.0.32)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /home/gitpod/.pyenv/versions/3.12.4/lib/python3.12/site-packages (from sqlalchemy) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from sqlalchemy) (3.0.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: psycopg2 in /home/gitpod/.pyenv/versions/3.12.4/lib/python3.12/site-packages (2.9.9)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: pymysql in /home/gitpod/.pyenv/versions/3.12.4/lib/python3.12/site-packages (1.1.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: cx_Oracle in /home/gitpod/.pyenv/versions/3.12.4/lib/python3.12/site-packages (8.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: pyodbc in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (5.1.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pandas\n",
    "!pip3 install sqlalchemy\n",
    "!pip3 install psycopg2  # For PostgreSQL\n",
    "!pip3 install pymysql   # For MySQL\n",
    "!pip3 install cx_Oracle # For Oracle \n",
    "!pip3 install pyodbc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "libodbc.so.2: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msqlalchemy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_engine, inspect\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyodbc\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Helper function to normalize names\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnormalize_names\u001b[39m(name):\n",
      "\u001b[0;31mImportError\u001b[0m: libodbc.so.2: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, inspect\n",
    "import pyodbc\n",
    "\n",
    "# Helper function to normalize names\n",
    "def normalize_names(name):\n",
    "    \"\"\"Normalize table and column names for comparison.\"\"\"\n",
    "    return name.lower().replace('_', '')\n",
    "\n",
    "# Example function to connect to a database (replace with actual credentials)\n",
    "def connect_to_database(server, database, username, password):\n",
    "    # Create a connection string using pyodbc\n",
    "    connection_string = f\"DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={server};DATABASE={database};UID={username};PWD={password}\"\n",
    "    \n",
    "    # Create a SQLAlchemy engine using the connection string\n",
    "    engine = create_engine(f\"mssql+pyodbc:///?odbc_connect={connection_string}\")\n",
    "    \n",
    "    # Return the engine connection\n",
    "    return engine.connect()\n",
    "\n",
    "# Example usage:\n",
    "server = \"MSSQLSERVER01\"\n",
    "database = \"ORACLE_EBS_HACK\"\n",
    "username = \"Sanap2\"\n",
    "password = \"Rahul123@\"\n",
    "\n",
    "connection = connect_to_database(server, database, username, password)\n",
    "\n",
    "# Now you can use the connection to query the database\n",
    "# For example:\n",
    "df = pd.read_sql_query(\"SELECT * FROM your_table_name\", connection)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schema Extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_schema(db_connection):\n",
    "    \"\"\"Extracts schema information (tables, columns, data types) from a database.\"\"\"\n",
    "    schema = {}\n",
    "    inspector = inspect(db_connection)\n",
    "\n",
    "    for table_name in inspector.get_table_names():\n",
    "        columns = inspector.get_columns(table_name)\n",
    "        schema[table_name] = [{'name': col['name'], 'data_type': col['type'], 'length': col.get('length')} for col in columns]\n",
    "    \n",
    "    return schema\n",
    "\n",
    "# Example usage (replace with actual database connections)\n",
    "# source_db_conn = connect_to_database(\"source_db_connection_string\")\n",
    "# target_db_conn = connect_to_database(\"target_db_connection_string\")\n",
    "# source_schema = extract_schema(source_db_conn)\n",
    "# target_schema = extract_schema(target_db_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shema Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_schemas(source_schema, target_schema):\n",
    "    \"\"\"Compares the source and target schemas and identifies potential mappings.\"\"\"\n",
    "    mappings = []\n",
    "    for source_table, source_columns in source_schema.items():\n",
    "        for target_table, target_columns in target_schema.items():\n",
    "            if tables_are_similar(source_table, target_table):\n",
    "                for source_column in source_columns:\n",
    "                    for target_column in target_columns:\n",
    "                        if columns_are_similar(source_column, target_column):\n",
    "                            mapping_type = determine_mapping_type(source_column, target_column)\n",
    "                            mappings.append({\n",
    "                                'source_table': source_table, \n",
    "                                'source_column': source_column['name'],\n",
    "                                'target_table': target_table, \n",
    "                                'target_column': target_column['name'],\n",
    "                                'mapping_type': mapping_type\n",
    "                            })\n",
    "    return mappings\n",
    "\n",
    "def tables_are_similar(source_table, target_table):\n",
    "    \"\"\"Determines if two tables are similar based on normalized names.\"\"\"\n",
    "    return normalize_names(source_table) == normalize_names(target_table)\n",
    "\n",
    "def columns_are_similar(source_column, target_column):\n",
    "    \"\"\"Determines if two columns are similar based on name, data type, and length.\"\"\"\n",
    "    return (normalize_names(source_column['name']) == normalize_names(target_column['name']) and\n",
    "            source_column['data_type'] == target_column['data_type'] and\n",
    "            (source_column['length'] == target_column['length'] or \n",
    "             source_column['length'] is None or \n",
    "             target_column['length'] is None))\n",
    "\n",
    "def determine_mapping_type(source_column, target_column):\n",
    "    \"\"\"Determines the type of mapping (EQ or SQL) based on column data types.\"\"\"\n",
    "    if source_column['data_type'] == target_column['data_type']:\n",
    "        return \"EQ\"\n",
    "    else:\n",
    "        return \"SQL\"\n",
    "\n",
    "# Example comparison\n",
    "# mappings = compare_schemas(source_schema, target_schema)\n",
    "# print(mappings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Value Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sql_mapping(source_column, target_column):\n",
    "    \"\"\"Generates SQL transformation logic if needed.\"\"\"\n",
    "    if source_column['data_type'] == 'DATE' and target_column['data_type'] == 'VARCHAR':\n",
    "        return f\"TO_CHAR({source_column['name']}, 'YYYY-MM-DD')\"\n",
    "    # Add more transformation rules as necessary\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mapping_report(mappings):\n",
    "    \"\"\"Generates a mapping report as a DataFrame.\"\"\"\n",
    "    df = pd.DataFrame(mappings)\n",
    "    return df\n",
    "\n",
    "# Example output\n",
    "# report = generate_mapping_report(mappings)\n",
    "# report.to_csv('mapping_report.csv', index=False)\n",
    "# print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all Pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(source_db_conn, target_db_conn):\n",
    "    # Extract schemas\n",
    "    source_schema = extract_schema(source_db_conn)\n",
    "    target_schema = extract_schema(target_db_conn)\n",
    "    \n",
    "    # Compare schemas and generate mappings\n",
    "    mappings = compare_schemas(source_schema, target_schema)\n",
    "    \n",
    "    # Generate and output the mapping report\n",
    "    report = generate_mapping_report(mappings)\n",
    "    \n",
    "    # Save the report to a file or display it\n",
    "    report.to_csv('mapping_report.csv', index=False)\n",
    "    print(report)\n",
    "\n",
    "# Example execution\n",
    "# source_db_conn = connect_to_database(\"source_db_connection_string\")\n",
    "# target_db_conn = connect_to_database(\"target_db_connection_string\")\n",
    "# main(source_db_conn, target_db_conn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
